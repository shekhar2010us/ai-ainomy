{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import cycle, islice\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.tools.plotting import parallel_coordinates\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. K-means cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_file = '../data/weather_clustering.csv'\n",
    "dataset = pd.read_csv(data_file)\n",
    "print ('Data shape: ', dataset.shape)\n",
    "print ('Columns: ', dataset.columns)\n",
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# describe the dataset\n",
    "dataset.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Data Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print ('Zero rain accumulation: ', dataset[dataset['rain_accumulation'] == 0].shape)\n",
    "print ('NaN rain accumulation: \\t', dataset[dataset['rain_accumulation'].isna()].shape)\n",
    "\n",
    "print ('\\nZero rain duration: \\t', dataset[dataset['rain_duration'] == 0].shape)\n",
    "print ('NaN rain duration: \\t', dataset[dataset['rain_duration'].isna()].shape)\n",
    "\n",
    "print ('\\nCount number of rows for each column having NaN value')\n",
    "print (dataset.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop all the Rows with NaN in columns: 'rain_accumulation' & 'rain_duration'\n",
    "subset_cols = ['rain_accumulation', 'rain_duration']\n",
    "dataset_2 = dataset.dropna(subset = subset_cols)\n",
    "\n",
    "print ('\\nCount number of rows for each column having NaN value')\n",
    "print (dataset_2.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop all the Rows with NaN in any column\n",
    "subset_cols = dataset.columns\n",
    "dataset_2 = dataset.dropna(subset = dataset.columns)\n",
    "\n",
    "print ('\\nCount number of rows for each column having NaN value')\n",
    "print (dataset_2.isna().sum())\n",
    "print ('\\nShape of new dataset: ', dataset_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select subset of features to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = ['air_pressure', 'air_temp', 'avg_wind_direction', 'avg_wind_speed', 'max_wind_direction', \n",
    "        'max_wind_speed','relative_humidity']\n",
    "\n",
    "select_df = dataset_2[features]\n",
    "print ('Shape of select_df: ', select_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the features\n",
    "-- `Previously we used MinMaxScaler, let's use StandardScaler now` <br>\n",
    "<br>\n",
    "__MinMaxScaler:__ `For each value in a feature, MinMaxScaler subtracts the minimum value in the feature and then divides by the range. The range is the difference between the original maximum and original minimum.`\n",
    "<br>\n",
    "__StandardScaler:__ `standardizes a feature by subtracting the mean and then scaling to unit variance. Unit variance means dividing all the values by the standard deviation.`\n",
    "<br>\n",
    "Properties: `StandardScaler does distort the relative distances between the feature values, but MinMaxScaler do not.`\n",
    "<br>\n",
    "<br> Choose your scaler wisely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(select_df)\n",
    "print ('X shape: ', X.shape, '\\n')\n",
    "sample_records = X[0:3].tolist()\n",
    "for i in range(len(sample_records)):\n",
    "    print (str(i) + \" >> \" + str(sample_records[i]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=12)\n",
    "model = kmeans.fit(X)\n",
    "print(\"model\\n\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "centers = model.cluster_centers_\n",
    "print ('Centroid shape: ', centers.shape)\n",
    "print ('\\nCentroid space: \\n', centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function that creates a DataFrame with a column for Cluster Number\n",
    "def pd_centers(featuresUsed, centers):\n",
    "    colNames = list(featuresUsed)\n",
    "    colNames.append('cluster_number')\n",
    "    \n",
    "    # Zip with a column called 'prediction' (index)\n",
    "    Z = [np.append(A, index) for index, A in enumerate(centers)]\n",
    "    \n",
    "    # Convert to pandas data frame for plotting\n",
    "    P = pd.DataFrame(Z, columns=colNames)\n",
    "    P['cluster_number'] = P['cluster_number'].astype(int)\n",
    "    return P\n",
    "\n",
    "# Function that creates Parallel Plots\n",
    "def parallel_plot(data):\n",
    "    my_colors = list(islice(cycle(['b', 'r', 'g', 'y', 'k']), None, len(data)))\n",
    "    plt.figure(figsize=(15,8)).gca().axes.set_ylim([-3,+3])\n",
    "    parallel_coordinates(data, 'cluster_number', color = my_colors, marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# value of centroid based on features\n",
    "P = pd_centers(features, centers)\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## DRY DAYS\n",
    "dry_days_centroid = P[P['relative_humidity'] < -0.5]\n",
    "print ('\\nDRY DAYS Centroid')\n",
    "print (dry_days_centroid)\n",
    "\n",
    "## WARM DAYS\n",
    "warm_days_centroid = P[P['air_temp'] > 0.5]\n",
    "print ('\\n\\nWARM DAYS Centroid')\n",
    "print (warm_days_centroid)\n",
    "\n",
    "## COOL DAYS\n",
    "cool_days_centroid = P[(P['relative_humidity'] > 0.5) & (P['air_temp'] < 0.5)]\n",
    "print ('\\n\\nCOOL DAYS Centroid')\n",
    "print (cool_days_centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parallel_plot(dry_days_centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parallel_plot(warm_days_centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parallel_plot(cool_days_centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
